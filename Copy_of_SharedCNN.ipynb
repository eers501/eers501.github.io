{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of SharedCNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "metadata": {
      "interpreter": {
        "hash": "78fd0277e36773bb158a357d8ef2d0dc0756109768316a11fab4faf06629a7c2"
      }
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eers501/eers501.github.io/blob/main/Copy_of_SharedCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIf2TlPZlej6"
      },
      "source": [
        "#@markdown # Hyper-parameter Tuning\n",
        "\n",
        "# Define some global consts\n",
        "# Dropout rates in the network\n",
        "DROPOUT_RATE_CONV = 0 #@param{type:\"slider\", min:0.0, max:1.0, step:0.05}\n",
        "DROPOUT_RATE_DENSE = 0.6 #@param{type:\"slider\", min:0.0, max:1.0, step:0.05}\n",
        "\n",
        "# Learning rate\n",
        "LEARNING_RATE = 0.0002 #@param{type:\"slider\", min:0.0001, max:0.001, step: 0.0001}\n",
        "\n",
        "# The number of batches\n",
        "BATCH_SIZE = 2048 #@param{type:\"slider\", min:256, max:2048, step:256}\n",
        "\n",
        "# Number of epochs to run\n",
        "EPOCHS = 80 #@param{type:\"slider\", min:0, max:300, step:10}\n",
        "\n",
        "END_CALLBACK = \"Iterative Improvement\" #@param [\"Iterative Improvement\", \"Target Accuracy\", \"None\"]\n",
        "DESIRED_ACCURACY = 0.9 #@param{type:\"slider\", min:0.8, max: 0.98, step:0.01}\n",
        "\n",
        "# If it hasn't hit the desired accuracy after 1000 runs, it probably never will\n",
        "if END_CALLBACK != \"None\":\n",
        "  EPOCHS = 1000"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SVNR-yGollO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae80fb2c-13ad-43d9-9c5f-bee819500023"
      },
      "source": [
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"Tensorflow version %s\" % tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version 2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIiizkf04j7p",
        "outputId": "9e060716-cf7e-4327-8f62-f2df4f03dda1"
      },
      "source": [
        "# GPU info\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Apr 30 14:55:35 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    37W / 300W |  12205MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUq6YituosQv"
      },
      "source": [
        "# Load the dataset\n",
        "cifar10 = tf.keras.datasets.cifar10\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIV8J_I-otnD"
      },
      "source": [
        "# Normalise the image values 0.0-1.0\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-adRsqR5c8q"
      },
      "source": [
        "# Augment the training data using a Keras ImageDataGenerator\n",
        "data_generator = ImageDataGenerator(\n",
        "    rotation_range = 15,\n",
        "    horizontal_flip = True,\n",
        "    width_shift_range = 0.2,\n",
        "    height_shift_range = 0.2,\n",
        "    rescale=None,\n",
        "    fill_mode=\"nearest\"\n",
        ")\n",
        "\n",
        "# Fit the data generator to the provided images (pre-computes transforms)\n",
        "data_generator.fit(train_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_KGh9815V-i"
      },
      "source": [
        "# Create the testing dataset\n",
        "testing_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6662EmjpBTs"
      },
      "source": [
        "# Define the model architecture\n",
        "model = Sequential([\n",
        "    Conv2D(64, 3, activation='relu', input_shape=(32, 32, 3), padding='same'),\n",
        "    Conv2D(64, 3, activation='relu', padding='same'),\n",
        "    MaxPooling2D(),\n",
        "    Dropout(DROPOUT_RATE_CONV),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Conv2D(128, 3, activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(128, 3, activation='relu', padding='same'),\n",
        "    MaxPooling2D(),\n",
        "    Dropout(DROPOUT_RATE_CONV),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Conv2D(256, 3, activation='relu', padding='same'),\n",
        "    Dropout(DROPOUT_RATE_CONV), # 0.25\n",
        "    BatchNormalization(),\n",
        "    Conv2D(256, 3, activation='relu', padding='same'),\n",
        "    Dropout(DROPOUT_RATE_CONV), # 0.25\n",
        "    MaxPooling2D(),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Conv2D(512, 3, activation='relu', padding='same'),\n",
        "    Dropout(DROPOUT_RATE_CONV), # 0.5\n",
        "    BatchNormalization(),\n",
        "    Conv2D(512, 3, activation='relu', padding='same'),\n",
        "    Dropout(DROPOUT_RATE_CONV), # 0.6\n",
        "    MaxPooling2D(),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(2048, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(DROPOUT_RATE_DENSE),\n",
        "    Dense(10, activation=tf.keras.activations.softmax)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBWxLvj0pCCM"
      },
      "source": [
        "# Compile the model with the AMSGrad variant of the Adam optimiser,\n",
        "# using Sparse Categorical Crossentropy as a loss function\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE, amsgrad=True),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy(\"accuracy\")])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKQ2IUWtNq5u"
      },
      "source": [
        "def save_model(model):\n",
        "  SAVE_TO_DRIVE = True #@param [\"True\", \"False\"] {type:\"raw\"}\n",
        "\n",
        "  filepath = \"\"\n",
        "\n",
        "  if (SAVE_TO_DRIVE):\n",
        "    # Save the model to Google Drive\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    filepath = \"drive/MyDrive/tf-models/cifar10-classifier-\"\n",
        "    filepath += str(int(test_acc * 100))\n",
        "  else:\n",
        "    filepath = \"tf-models/cifar10-classifier-\"\n",
        "    filepath += str(int(test_acc * 100))\n",
        "\n",
        "  model.save(filepath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACLCK0BqpEXl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b26f8f9d-b782-4277-dcaf-f483862651ed"
      },
      "source": [
        "# Train the model on the training data\n",
        "callbacks=None\n",
        "\n",
        "next_target_accuracy = DESIRED_ACCURACY\n",
        "\n",
        "if END_CALLBACK == \"Target Accuracy\":\n",
        "  print(\"Using target accuracy of %f\\%%\" % (DESIRED_ACCURACY * 100.0))\n",
        "  class AccuracyCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "      if (logs.get('val_accuracy') > DESIRED_ACCURACY):\n",
        "        print(\"Stopping training as desired accuracy has been reached\")\n",
        "        self.model.stop_training = True\n",
        "\n",
        "  callbacks = AccuracyCallback() \n",
        "\n",
        "elif END_CALLBACK == \"Iterative Improvement\":\n",
        "  print(\"Using iterative improvement.  Initial target: %f%%\" % (next_target_accuracy * 100.0))\n",
        "  class IterativeImprovementCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "      global next_target_accuracy\n",
        "      if (logs.get('val_accuracy') > next_target_accuracy):\n",
        "        print(\"Reached next milestone %f.  Saving and incrementing target by 1.\" % (next_target_accuracy))\n",
        "        next_target_accuracy += 1.0\n",
        "        save_model(self.model)\n",
        "\n",
        "  callbacks = IterativeImprovementCallback()\n",
        "\n",
        "else:\n",
        "  print(\"Not using callbacks\")\n",
        "  class NoneCallback(tf.keras.callbacks.Callback):\n",
        "      def on_epoch_end(self, epoch, logs={}):\n",
        "        pass\n",
        "\n",
        "  callbacks = NoneCallback()\n",
        "  \n",
        "\n",
        "history = model.fit(\n",
        "    x=data_generator.flow(train_images, train_labels, BATCH_SIZE)\n",
        "    , epochs=EPOCHS\n",
        "    , steps_per_epoch=len(train_images)/BATCH_SIZE\n",
        "    , validation_data=testing_dataset\n",
        "    , callbacks=[callbacks]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using iterative improvement.  Initial target: 90.000000%\n",
            "Epoch 1/1000\n",
            "24/24 [==============================] - 23s 901ms/step - loss: 3.1137 - accuracy: 0.2519 - val_loss: 2.3315 - val_accuracy: 0.1000\n",
            "Epoch 2/1000\n",
            "24/24 [==============================] - 22s 896ms/step - loss: 2.2233 - accuracy: 0.3763 - val_loss: 2.4174 - val_accuracy: 0.1000\n",
            "Epoch 3/1000\n",
            "24/24 [==============================] - 22s 908ms/step - loss: 1.8978 - accuracy: 0.4321 - val_loss: 2.5516 - val_accuracy: 0.1000\n",
            "Epoch 4/1000\n",
            "24/24 [==============================] - 22s 896ms/step - loss: 1.7157 - accuracy: 0.4682 - val_loss: 2.7388 - val_accuracy: 0.1001\n",
            "Epoch 5/1000\n",
            "24/24 [==============================] - 22s 888ms/step - loss: 1.5754 - accuracy: 0.4987 - val_loss: 3.1105 - val_accuracy: 0.1010\n",
            "Epoch 6/1000\n",
            "24/24 [==============================] - 22s 894ms/step - loss: 1.4473 - accuracy: 0.5303 - val_loss: 3.3744 - val_accuracy: 0.1002\n",
            "Epoch 7/1000\n",
            "24/24 [==============================] - 22s 884ms/step - loss: 1.3610 - accuracy: 0.5572 - val_loss: 3.8707 - val_accuracy: 0.1010\n",
            "Epoch 8/1000\n",
            "24/24 [==============================] - 22s 891ms/step - loss: 1.2959 - accuracy: 0.5734 - val_loss: 4.2020 - val_accuracy: 0.1535\n",
            "Epoch 9/1000\n",
            "24/24 [==============================] - 22s 900ms/step - loss: 1.2253 - accuracy: 0.5932 - val_loss: 4.9372 - val_accuracy: 0.1149\n",
            "Epoch 10/1000\n",
            "24/24 [==============================] - 22s 886ms/step - loss: 1.1816 - accuracy: 0.6061 - val_loss: 5.9623 - val_accuracy: 0.1016\n",
            "Epoch 11/1000\n",
            "24/24 [==============================] - 22s 881ms/step - loss: 1.1399 - accuracy: 0.6168 - val_loss: 6.7711 - val_accuracy: 0.1070\n",
            "Epoch 12/1000\n",
            "24/24 [==============================] - 22s 885ms/step - loss: 1.0932 - accuracy: 0.6320 - val_loss: 7.9123 - val_accuracy: 0.1011\n",
            "Epoch 13/1000\n",
            "24/24 [==============================] - 23s 928ms/step - loss: 1.0524 - accuracy: 0.6451 - val_loss: 7.8093 - val_accuracy: 0.1094\n",
            "Epoch 14/1000\n",
            "24/24 [==============================] - 22s 891ms/step - loss: 1.0335 - accuracy: 0.6514 - val_loss: 8.0174 - val_accuracy: 0.1070\n",
            "Epoch 15/1000\n",
            "24/24 [==============================] - 22s 896ms/step - loss: 1.0003 - accuracy: 0.6701 - val_loss: 7.6065 - val_accuracy: 0.1391\n",
            "Epoch 16/1000\n",
            "24/24 [==============================] - 22s 895ms/step - loss: 0.9606 - accuracy: 0.6723 - val_loss: 9.0939 - val_accuracy: 0.1082\n",
            "Epoch 17/1000\n",
            "24/24 [==============================] - 22s 892ms/step - loss: 0.9411 - accuracy: 0.6852 - val_loss: 9.1771 - val_accuracy: 0.1065\n",
            "Epoch 18/1000\n",
            "24/24 [==============================] - 22s 887ms/step - loss: 0.9290 - accuracy: 0.6869 - val_loss: 8.4379 - val_accuracy: 0.1245\n",
            "Epoch 19/1000\n",
            "24/24 [==============================] - 22s 896ms/step - loss: 0.8925 - accuracy: 0.6987 - val_loss: 6.9986 - val_accuracy: 0.1706\n",
            "Epoch 20/1000\n",
            "24/24 [==============================] - 22s 887ms/step - loss: 0.8574 - accuracy: 0.7090 - val_loss: 6.6606 - val_accuracy: 0.1458\n",
            "Epoch 21/1000\n",
            "24/24 [==============================] - 22s 881ms/step - loss: 0.8413 - accuracy: 0.7173 - val_loss: 6.0582 - val_accuracy: 0.1898\n",
            "Epoch 22/1000\n",
            "24/24 [==============================] - 22s 883ms/step - loss: 0.8038 - accuracy: 0.7248 - val_loss: 5.2829 - val_accuracy: 0.1930\n",
            "Epoch 23/1000\n",
            "24/24 [==============================] - 22s 898ms/step - loss: 0.7969 - accuracy: 0.7280 - val_loss: 3.7674 - val_accuracy: 0.3019\n",
            "Epoch 24/1000\n",
            "24/24 [==============================] - 22s 885ms/step - loss: 0.7815 - accuracy: 0.7340 - val_loss: 2.6363 - val_accuracy: 0.4030\n",
            "Epoch 25/1000\n",
            "24/24 [==============================] - 22s 879ms/step - loss: 0.7587 - accuracy: 0.7396 - val_loss: 2.1106 - val_accuracy: 0.4608\n",
            "Epoch 26/1000\n",
            "24/24 [==============================] - 21s 867ms/step - loss: 0.7415 - accuracy: 0.7420 - val_loss: 2.5200 - val_accuracy: 0.4246\n",
            "Epoch 27/1000\n",
            "24/24 [==============================] - 22s 886ms/step - loss: 0.7052 - accuracy: 0.7538 - val_loss: 1.5189 - val_accuracy: 0.5918\n",
            "Epoch 28/1000\n",
            "24/24 [==============================] - 22s 883ms/step - loss: 0.6919 - accuracy: 0.7571 - val_loss: 1.4508 - val_accuracy: 0.6047\n",
            "Epoch 29/1000\n",
            "24/24 [==============================] - 21s 891ms/step - loss: 0.6824 - accuracy: 0.7647 - val_loss: 0.9469 - val_accuracy: 0.6969\n",
            "Epoch 30/1000\n",
            "24/24 [==============================] - 22s 881ms/step - loss: 0.6619 - accuracy: 0.7679 - val_loss: 1.0002 - val_accuracy: 0.6921\n",
            "Epoch 31/1000\n",
            "24/24 [==============================] - 21s 865ms/step - loss: 0.6408 - accuracy: 0.7744 - val_loss: 0.9803 - val_accuracy: 0.6944\n",
            "Epoch 32/1000\n",
            "24/24 [==============================] - 22s 879ms/step - loss: 0.6351 - accuracy: 0.7760 - val_loss: 0.8332 - val_accuracy: 0.7357\n",
            "Epoch 33/1000\n",
            "24/24 [==============================] - 22s 889ms/step - loss: 0.6182 - accuracy: 0.7840 - val_loss: 0.7413 - val_accuracy: 0.7570\n",
            "Epoch 34/1000\n",
            "24/24 [==============================] - 22s 885ms/step - loss: 0.5945 - accuracy: 0.7922 - val_loss: 0.9198 - val_accuracy: 0.7129\n",
            "Epoch 35/1000\n",
            "24/24 [==============================] - 21s 877ms/step - loss: 0.6015 - accuracy: 0.7907 - val_loss: 0.9467 - val_accuracy: 0.7039\n",
            "Epoch 36/1000\n",
            "24/24 [==============================] - 22s 898ms/step - loss: 0.5783 - accuracy: 0.7970 - val_loss: 0.7548 - val_accuracy: 0.7520\n",
            "Epoch 37/1000\n",
            "24/24 [==============================] - 22s 889ms/step - loss: 0.5593 - accuracy: 0.8057 - val_loss: 0.7855 - val_accuracy: 0.7436\n",
            "Epoch 38/1000\n",
            "24/24 [==============================] - 22s 879ms/step - loss: 0.5611 - accuracy: 0.8029 - val_loss: 0.6002 - val_accuracy: 0.7942\n",
            "Epoch 39/1000\n",
            "24/24 [==============================] - 22s 889ms/step - loss: 0.5442 - accuracy: 0.8079 - val_loss: 0.6705 - val_accuracy: 0.7779\n",
            "Epoch 40/1000\n",
            "24/24 [==============================] - 21s 875ms/step - loss: 0.5284 - accuracy: 0.8127 - val_loss: 0.7049 - val_accuracy: 0.7668\n",
            "Epoch 41/1000\n",
            "24/24 [==============================] - 22s 885ms/step - loss: 0.5186 - accuracy: 0.8158 - val_loss: 0.8644 - val_accuracy: 0.7358\n",
            "Epoch 42/1000\n",
            "24/24 [==============================] - 22s 885ms/step - loss: 0.5190 - accuracy: 0.8168 - val_loss: 0.6330 - val_accuracy: 0.7909\n",
            "Epoch 43/1000\n",
            "24/24 [==============================] - 21s 877ms/step - loss: 0.5135 - accuracy: 0.8190 - val_loss: 0.6903 - val_accuracy: 0.7782\n",
            "Epoch 44/1000\n",
            "24/24 [==============================] - 21s 870ms/step - loss: 0.4986 - accuracy: 0.8273 - val_loss: 0.7012 - val_accuracy: 0.7673\n",
            "Epoch 45/1000\n",
            "24/24 [==============================] - 22s 878ms/step - loss: 0.4991 - accuracy: 0.8239 - val_loss: 0.6657 - val_accuracy: 0.7826\n",
            "Epoch 46/1000\n",
            "24/24 [==============================] - 21s 891ms/step - loss: 0.4778 - accuracy: 0.8324 - val_loss: 0.6652 - val_accuracy: 0.7836\n",
            "Epoch 47/1000\n",
            "24/24 [==============================] - 21s 874ms/step - loss: 0.4670 - accuracy: 0.8338 - val_loss: 0.6675 - val_accuracy: 0.7826\n",
            "Epoch 48/1000\n",
            "24/24 [==============================] - 21s 872ms/step - loss: 0.4556 - accuracy: 0.8406 - val_loss: 0.6254 - val_accuracy: 0.7905\n",
            "Epoch 49/1000\n",
            "24/24 [==============================] - 21s 857ms/step - loss: 0.4633 - accuracy: 0.8341 - val_loss: 0.6841 - val_accuracy: 0.7932\n",
            "Epoch 50/1000\n",
            "24/24 [==============================] - 22s 884ms/step - loss: 0.4547 - accuracy: 0.8397 - val_loss: 0.5970 - val_accuracy: 0.8043\n",
            "Epoch 51/1000\n",
            "24/24 [==============================] - 22s 879ms/step - loss: 0.4378 - accuracy: 0.8460 - val_loss: 0.5876 - val_accuracy: 0.8069\n",
            "Epoch 52/1000\n",
            "24/24 [==============================] - 21s 870ms/step - loss: 0.4333 - accuracy: 0.8482 - val_loss: 0.6101 - val_accuracy: 0.8013\n",
            "Epoch 53/1000\n",
            "24/24 [==============================] - 21s 878ms/step - loss: 0.4185 - accuracy: 0.8524 - val_loss: 0.5666 - val_accuracy: 0.8100\n",
            "Epoch 54/1000\n",
            "24/24 [==============================] - 21s 863ms/step - loss: 0.4219 - accuracy: 0.8518 - val_loss: 0.5726 - val_accuracy: 0.8142\n",
            "Epoch 55/1000\n",
            "24/24 [==============================] - 21s 867ms/step - loss: 0.4131 - accuracy: 0.8527 - val_loss: 0.6480 - val_accuracy: 0.7982\n",
            "Epoch 56/1000\n",
            "24/24 [==============================] - 21s 872ms/step - loss: 0.4007 - accuracy: 0.8578 - val_loss: 0.6035 - val_accuracy: 0.8079\n",
            "Epoch 57/1000\n",
            "24/24 [==============================] - 21s 862ms/step - loss: 0.4129 - accuracy: 0.8555 - val_loss: 0.6331 - val_accuracy: 0.7968\n",
            "Epoch 58/1000\n",
            "24/24 [==============================] - 22s 879ms/step - loss: 0.3880 - accuracy: 0.8623 - val_loss: 0.5479 - val_accuracy: 0.8244\n",
            "Epoch 59/1000\n",
            "24/24 [==============================] - 21s 873ms/step - loss: 0.3885 - accuracy: 0.8633 - val_loss: 0.5998 - val_accuracy: 0.8073\n",
            "Epoch 60/1000\n",
            "24/24 [==============================] - 21s 866ms/step - loss: 0.3816 - accuracy: 0.8653 - val_loss: 0.5740 - val_accuracy: 0.8120\n",
            "Epoch 61/1000\n",
            "24/24 [==============================] - 22s 882ms/step - loss: 0.3746 - accuracy: 0.8662 - val_loss: 0.6246 - val_accuracy: 0.8018\n",
            "Epoch 62/1000\n",
            "24/24 [==============================] - 21s 867ms/step - loss: 0.3695 - accuracy: 0.8688 - val_loss: 0.5873 - val_accuracy: 0.8165\n",
            "Epoch 63/1000\n",
            "24/24 [==============================] - 21s 856ms/step - loss: 0.3676 - accuracy: 0.8685 - val_loss: 0.5911 - val_accuracy: 0.8162\n",
            "Epoch 64/1000\n",
            "24/24 [============================>.] - ETA: 0s - loss: 0.3525 - accuracy: 0.8760"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cd4h4FvrpGsf"
      },
      "source": [
        "# Test model accuracy on test set\n",
        "test_loss, test_acc = model.evaluate(testing_dataset)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPAPPmiBKUJ7"
      },
      "source": [
        "# Save the final model if we haven't already been doing so\n",
        "if END_CALLBACK != \"Iterative Improvement\":\n",
        "  save_model(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4Y9KL2zutNA"
      },
      "source": [
        "# Plot accuracy against epochs\n",
        "plt.subplot(211)  \n",
        "plt.plot(history.history['accuracy'])  \n",
        "plt.plot(history.history['val_accuracy'])  \n",
        "plt.title('model accuracy')  \n",
        "plt.ylabel('accuracy')  \n",
        "plt.xlabel('epoch')  \n",
        "plt.legend(['train', 'test'], loc='upper left')  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWCWJgNkyXVl"
      },
      "source": [
        "# Plot loss against epochs\n",
        "plt.subplot(212)  \n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')  \n",
        "plt.ylabel('loss')  \n",
        "plt.xlabel('epoch')  \n",
        "plt.legend(['train', 'test'], loc='upper left')  \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBukjICTijh9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}